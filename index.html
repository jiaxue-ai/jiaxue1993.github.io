<!DOCTYPE html>
<html lang="en">
<head>
<title>Jia Xue, Rutgers University</title>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="https://use.fontawesome.com/65cdeb203c.js"></script>
<link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">

</head>
<body>

  <div class="container">
    <hr>
    <div class="row">
      <div class="col-xs-8">
        <div class="media">
          <div class="media-left">  <img src="img/jia.jpg" alt="..." width="115" height="115" class="media-object img-rounded"> </div>
          <div class="media-body">
            <h2 class="media-heading">Jia Xue</h2>
            I am a PhD student at <a href="http://www.ece.rutgers.edu/~kdana/">ECE Vision Lab</a>, Rutgers University. My advisor is <a href="http://www.ece.rutgers.edu/~kdana/dana.html">Professor Kristin Dana</a>. I obtained my bachelor degree from <a href="http://www.uestc.edu.cn">University of Electronic Science and Technology of China (UESTC)</a>. My research interests are machine learning and computer vision.
          </div>
        </div>
      </div>
      <div class="col-xs-3 well col-sm-3">
        <div class="row">
        <div class="col-lg-12">
        <h3>
        <a href="https://github.com/jiaxue1993" class="fa fa-github" aria-hidden="true"></a>
        <a href="https://www.linkedin.com/profile/view?id=AAMAABYG70UBIyc80rBZqpPUYoSUpdwjLXXMcQc&trk=hp-identity-name" class="fa fa-linkedin" aria-hidden="true"></a>
        <a href="mailto:jia.xue@rutgers.edu" class="fa fa-envelope" aria-hidden="true"></a>
        <a href="img/cvJiaXue.pdf">[ C.V. ]</a>
        </h3>
        </div>
        </div>
      </div>
      </div>
   </div>

  <hr>
  <div class="row">
    <div class="container">
    <div class="col-xs-10 col-sm-10">
    <h4>News</h4>
    <div class="news" style="overflow:auto; height:105px; padding-top: 20px;">
    <ul>
    <li>04/2018: One paper (first-authored) is accepted by <a href="https://web.northeastern.edu/smilelab/AMFG2018/">CVPR2018 Workshop</a>. See you at Salt Lake City, UTAH!
    <li>04/2018: I won the Graduate Assistant Professional Development Fund
    <li>03/2018: One paper (first-authored) is accepted by <a href="http://cvpr2018.thecvf.com/">CVPR2018</a>. See you at Salt Lake City, UTAH!
    <li>12/2017: I will serve as a reviewer for ECCV2018
    <li>10/2017: I won the Rutgers ECE Research Excellence Award
    <li>09/2017: I will serve as a reviewer for CVPR2018
    <li>10/2017: I won the Graduate Assistant Professional Development Fund
    <li>03/2017: I have two papers accepted by <a href="http://cvpr2017.thecvf.com/">CVPR2017</a>. See you at Honolulu, Hawaii!
    </ul>
     </div> 
    </div>
    </div>
  </div> 

    <hr>
    <div class="row">
    <div class="container">
     <div class="col-xs-12 col-sm-12">
        <h2>Publications</h2>
        <hr>
        <div class="row">
          <div class="col-xs-4 text-center"><img src="img/cvpr18.png" alt="..." width="230" height="115" class="media-object"> </div>
          <div class="col-xs-8">
           <h4>Deep Texture Manifold for Ground Terrain Recognition</h4>
              <b>Jia Xue</b>, 
              <a href="http://hangzh.com/">Hang Zhang</a>, 
              <a href="http://eceweb1.rutgers.edu/vision/dana.html">Kristin Dana</a>
              <br>
        <em>IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b></em>, 2018<br>
        <a href="https://arxiv.org/pdf/1803.10896.pdf">arXiv</a> |
        <a href="https://youtu.be/mEkEv7DEFVc">demo1</a> |
        <a href="https://youtu.be/_9J3q6acwT8">demo2</a> 
          </div>
        </div>
        <hr>
        <div class="row">
        	<div class="col-xs-4 text-center"><img src="img/cvpr17differential.png" alt="..." width="230" height="115" class="media-object"> </div>
        	<div class="col-xs-8">
        	 <h4>Differential Angular Imaging for Material Recognition</h4>
              <b>Jia Xue</b>, 
              <a href="http://hangzh.com/">Hang Zhang</a>, 
              <a href="http://eceweb1.rutgers.edu/vision/dana.html">Kristin Dana</a>, 
              <a href="https://www.cs.drexel.edu/~kon/">Ko Nishino</a>
              <br>
      	<em>IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b></em>, 2017<br>
        <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Xue_Differential_Angular_Imaging_CVPR_2017_paper.pdf">paper</a> |
        <a href="https://github.com/mrxue1993/Differential-Angular-Imaging-for-Material-Recognition">code</a> |
        <a href="http://eceweb1.rutgers.edu/vision/gts/gtos.html">project</a> 
        	</div>
        </div>
        <hr>
        <div class="row">
        	<div class="col-xs-4 text-center"><img src="img/cvpr17deep.png" alt="..." width="230" height="115" class="media-object"> </div>
        	<div class="col-xs-8">
        	 <h4>Deep TEN: Texture Encoding Network</h4>
              <a href="http://hangzh.com/">Hang Zhang</a>, 
              <b>Jia Xue</b>, 
              <a href="http://eceweb1.rutgers.edu/vision/dana.html">Kristin Dana</a>
              <br>
      	<em>IEEE Conference on Computer Vision and Pattern Recognition <b>(CVPR)</b></em>, 2017<br><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhang_Deep_TEN_Texture_CVPR_2017_paper.pdf">paper</a> |
        <a href="https://github.com/zhanghang1989/PyTorch-Encoding">code</a>
        	</div>
        </div>
    </div> 
   </div> 
   </div>

<hr>
<div class="row">
    <div class="container">
     <div class="col-xs-12 col-sm-12">
        <h2>Projects</h2>
        <hr>
        <div class="row">
          <div class="col-xs-5"><h4><a href="https://www.iarpa.gov/index.php/research-programs/core3d/216-research/current-research/core3d/baa">Creation of Operationally Realistic 3D Environment (CORE3D)</a></h4></div>
          <div class="col-xs-5">
            <h4 class="text-right"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>Nov 17 - Present</h4>
          </div>
        </div>
        <p>This project will develop models and algorithms to accurately and efficiently capture the 3D geometry and surface properties of objects on the Earth. Collaborating with Columbia University, Purdue University, Raytheon and Kitware. Our contribution is semantic material segmentation of satellite images. </p>
        <hr>
        <div class="row">
          <div class="col-xs-5"><h4><a href="http://ece.engr.rutgers.edu/node/2426">Seeing Surfaces: Actionable Surface Properties from Vision</a></h4></div>
          <div class="col-xs-5">
            <h4 class="text-right"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span>Nov 17 - Present</h4>
          </div>
        </div>
        <p>This project will develop models and algorithms for estimating actionable, physical properties of surfaces from their appearance for applications in scene understanding, robotic action planning, and efficient visual sensing. The research will address the fundamental question of how computer vision can anticipate the physical properties of a surface, laying the foundation for computational vision-for-action. The research activities are centered on four specific aims: 1) large-scale data collection of actionable physical properties and appearance measurements of everyday surfaces, 2) derivation of prediction models for deducing physical properties from local surface appearance, 3) integration of global semantic context including object and scene information, and 4) development of efficient appearance-capture optics and hardware for use in novel physics-from-appearance sensing. </p>
        <hr>
        <div class="row">
        	<div class="col-xs-5"><h4><a href="http://www.ece.rutgers.edu/news/matcam-camera-sees-materials">MatCam: A Camera that Sees Materials</a></h4></div>
        	<div class="col-xs-5">
        	  <h4 class="text-right"><span class="glyphicon glyphicon-calendar" aria-hidden="true"></span> Jan 15 â€“ Nov 17</h4>
        	</div>
        </div>
        <p>This project develops the first material camera, or MatCam, that outputs a per-pixel label of object material and its properties that can be used in visual computing tasks. In the everyday real world there are a vast number of materials that are useful to discern including concrete, metal, plastic, velvet, satin, water layer on asphalt, carpet, tile, wood, and marble. A device for identifying materials has important implications in developing new technologies. For example, a mobile robot may use a MatCam to determine whether the terrain is grass, gravel, pavement, or snow in order to optimize mechanical control. In e-commerce, the material composition of objects can be tagged by a MatCam for advertising and inventory. The potential applications are limitless in areas such as robotics, digital architecture, human-computer interaction, intelligent vehicles and advanced manufacturing. Furthermore, material maps have foundational importance in nearly all vision algorithms including segmentation, feature matching, scene recognition, image-based rendering, context-based search, and object recognition and motion estimation. The camera brings material recognition to the broader scientific and engineering communities, in a similar way that depth cameras are currently used in many fields outside of computer vision. </p>
      </div>
      </div>
</div>
<hr>
    <!-- <div class="row">
    <div class="container">
     <div class="col-xs-8 col-sm-8">
        <h4><a href="http://eceweb1.rutgers.edu/~kdana/index.html">Computer Vision Lab</a></h4>
        <b>Professor: </b>
			<b><a href="http://eceweb1.rutgers.edu/~kdana/dana.html">Kistin Dana</a></b> 
		<br>
		<b>PhD Students: </b>
			<b>Jia Xue</b>,
			<b><a href="https://ericwengrowski.com/">Eric Wengrowski</a></b>,
			<b><a href="http://hangzh.com/">Hang Zhang</a></b>,
			<b><a href="http://parneetk.github.io/">Parneet Kaur</a></b>
     </div>
     <div class="col-xs-4 col-sm-4">
        <a href="http://m.maploco.com/details/42b5q011"><img style="border:0px;" src="http://www.maploco.com/vmap/s/9611173.png"/></a>  
     </div> 
     </div>
     </div>
<hr> -->
  <div class="row">
    <div class="container">
    
      <div class="col-xs-12 col-sm-12">
        <a href="http://www.easycounter.com/">
        <img src="//www.easycounter.com/counter.php?jiaxue" border="0" alt="HTML Hit Counters"></a>
        </a>
        <p><i>unique visitors since Dec 2016</i></p>
      </div>
    </div>
  </div>
</footer>
<!-- jQuery (necessary for Bootstrap's JavaScript plugins) --> 
<script src="js/jquery-1.11.2.min.js"></script> 
<!-- Include all compiled plugins (below), or include individual files as needed --> 
<script src="js/bootstrap.min.js"></script>
</body>
</html>
